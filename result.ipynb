{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "union-fairy",
   "metadata": {},
   "source": [
    "# EPL Result Classification\n",
    "\n",
    "For this project, I will try to predict full-time result of the English Premier League match.\n",
    "\n",
    "The data comes from a Kaggle (https://www.kaggle.com/irkaal/english-premier-league-results) and I will use the \"results.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eligible-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from   sklearn.compose         import *\n",
    "from   sklearn.impute          import *\n",
    "from   sklearn.preprocessing   import *\n",
    "from   sklearn.ensemble        import RandomForestClassifier\n",
    "from   sklearn.neighbors       import KNeighborsClassifier\n",
    "from   sklearn.pipeline        import Pipeline\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.model_selection import RandomizedSearchCV\n",
    "from   sklearn.metrics         import f1_score\n",
    "from   sklearn.metrics         import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-april",
   "metadata": {},
   "source": [
    "## Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technical-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results.csv', parse_dates=['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chinese-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14 00:00:00+00:00</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14 00:00:00+00:00</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>QPR</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14 00:00:00+00:00</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14 00:00:00+00:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-94</td>\n",
       "      <td>1993-08-14 00:00:00+00:00</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season                  DateTime     HomeTeam        AwayTeam  FTHG  FTAG  \\\n",
       "0  1993-94 1993-08-14 00:00:00+00:00      Arsenal        Coventry     0     3   \n",
       "1  1993-94 1993-08-14 00:00:00+00:00  Aston Villa             QPR     4     1   \n",
       "2  1993-94 1993-08-14 00:00:00+00:00      Chelsea       Blackburn     1     2   \n",
       "3  1993-94 1993-08-14 00:00:00+00:00    Liverpool  Sheffield Weds     2     0   \n",
       "4  1993-94 1993-08-14 00:00:00+00:00     Man City           Leeds     1     1   \n",
       "\n",
       "  FTR  HTHG  HTAG  HTR  ... HST  AST  HC  AC  HF  AF  HY  AY  HR  AR  \n",
       "0   A   NaN   NaN  NaN  ... NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1   H   NaN   NaN  NaN  ... NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2   A   NaN   NaN  NaN  ... NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3   H   NaN   NaN  NaN  ... NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4   D   NaN   NaN  NaN  ... NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pointed-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 1993 to 2000, there is only result data, therefore, I will use data from 2000\n",
    "data = data.iloc[2824:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blank-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month from DateTime column\n",
    "data['Month'] = data['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "protected-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target\n",
    "y = data[['FTR']].rename(columns={'FTR':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "discrete-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "X = data.drop(['Season', 'DateTime', 'FTR', 'FTHG', 'FTAG'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consistent-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target\n",
    "le = LabelEncoder()\n",
    "le.fit(y['label'])\n",
    "y = le.transform(y['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-venue",
   "metadata": {},
   "source": [
    "## Fit scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "herbal-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['HomeTeam', 'AwayTeam', 'HTR', 'Month', 'Referee']\n",
    "cat_pipe = Pipeline(steps = [('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                             ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "numerical = ['HTHG','HTAG','HS','AS','HST','AST','HC','AC','HF','AF','HY','AY','HR','AR']\n",
    "num_pipe = Pipeline(steps = [('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "                             ('scaler',  StandardScaler(with_mean=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', cat_pipe, categorical),\n",
    "                                               ('num', num_pipe, numerical)],\n",
    "                                 remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "promotional-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-nation",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cardiac-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [('pre', preprocessor),\n",
    "                         ('kn', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "spread-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(kn__algorithm        = ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                       kn__weights          = ['uniform', 'distance'],\n",
    "                       kn__leaf_size        = range(1, 50),\n",
    "                       kn__n_neighbors      = range(1, 100))\n",
    "\n",
    "kn_rand_cv = RandomizedSearchCV(estimator=pipe, \n",
    "                                 param_distributions=hyperparameters, \n",
    "                                 n_iter=25,\n",
    "                                 cv=5, \n",
    "                                 n_jobs=-1,\n",
    "                                 verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "african-passing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('pre',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('cat',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                               ('encoder',\n",
       "                                                                                                OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                              sparse=False))]),\n",
       "                                                                               ['HomeTeam',\n",
       "                                                                                'AwayTeam',\n",
       "                                                                                'HTR',\n",
       "                                                                                'Month',\n",
       "                                                                                'Referee']),\n",
       "                                                                              ('num',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer...\n",
       "                                                                                                StandardScaler(with_mean=False))]),\n",
       "                                                                               ['HTHG',\n",
       "                                                                                'HTAG',\n",
       "                                                                                'HS',\n",
       "                                                                                'AS',\n",
       "                                                                                'HST',\n",
       "                                                                                'AST',\n",
       "                                                                                'HC',\n",
       "                                                                                'AC',\n",
       "                                                                                'HF',\n",
       "                                                                                'AF',\n",
       "                                                                                'HY',\n",
       "                                                                                'AY',\n",
       "                                                                                'HR',\n",
       "                                                                                'AR'])])),\n",
       "                                             ('kn', KNeighborsClassifier())]),\n",
       "                   n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'kn__algorithm': ['auto', 'ball_tree',\n",
       "                                                          'kd_tree', 'brute'],\n",
       "                                        'kn__leaf_size': range(1, 50),\n",
       "                                        'kn__n_neighbors': range(1, 100),\n",
       "                                        'kn__weights': ['uniform', 'distance']},\n",
       "                   verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_rand_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "favorite-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_rand_cv.best_estimator_.fit(X_train, y_train)\n",
    "y_pred   = kn_rand_cv.best_estimator_.predict(X_test)\n",
    "f1_test  = f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "built-bargain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.632"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(f1_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-season",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "extensive-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [('pre', preprocessor),\n",
    "                         ('rf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "better-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(rf__max_depth        = range(1, 100),\n",
    "                       rf__criterion        = ['gini', 'entropy'],\n",
    "                       rf__min_samples_leaf = range(1, 15),\n",
    "                       rf__n_estimators     = [20, 50, 80, 100, 200])\n",
    "\n",
    "rf_rand_cv = RandomizedSearchCV(estimator=pipe, \n",
    "                                 param_distributions=hyperparameters, \n",
    "                                 n_iter=25,\n",
    "                                 cv=5, \n",
    "                                 n_jobs=-1,\n",
    "                                 verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "medieval-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('pre',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('cat',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                               ('encoder',\n",
       "                                                                                                OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                              sparse=False))]),\n",
       "                                                                               ['HomeTeam',\n",
       "                                                                                'AwayTeam',\n",
       "                                                                                'HTR',\n",
       "                                                                                'Month',\n",
       "                                                                                'Referee']),\n",
       "                                                                              ('num',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer...\n",
       "                                                                                               ('scaler',\n",
       "                                                                                                StandardScaler(with_mean=False))]),\n",
       "                                                                               ['HTHG',\n",
       "                                                                                'HTAG',\n",
       "                                                                                'HS',\n",
       "                                                                                'AS',\n",
       "                                                                                'HST',\n",
       "                                                                                'AST',\n",
       "                                                                                'HC',\n",
       "                                                                                'AC',\n",
       "                                                                                'HF',\n",
       "                                                                                'AF',\n",
       "                                                                                'HY',\n",
       "                                                                                'AY',\n",
       "                                                                                'HR',\n",
       "                                                                                'AR'])])),\n",
       "                                             ('rf', RandomForestClassifier())]),\n",
       "                   n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'rf__criterion': ['gini', 'entropy'],\n",
       "                                        'rf__max_depth': range(1, 100),\n",
       "                                        'rf__min_samples_leaf': range(1, 15),\n",
       "                                        'rf__n_estimators': [20, 50, 80, 100,\n",
       "                                                             200]},\n",
       "                   verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "charged-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rand_cv.best_estimator_.fit(X_train, y_train)\n",
    "y_pred   = rf_rand_cv.best_estimator_.predict(X_test)\n",
    "f1_test  = f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "elder-rendering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.657"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(f1_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-monster",
   "metadata": {},
   "source": [
    "RandomForestClassifier shows better F1 score than KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-costume",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "RandomForestClassifier's prediction seems better than the KNeighborsClassifier's prediction. One of the reason I think is that, there are huge number of categorical values in the data and they are the most important features in the model. Therefore, as the RandomForestClassifier set the max_depth as 93 which is high, it processed categorical features very well compared to the KNeighborsClassifier. Hyperparamers used are summarized below. It used maximum n_estimators that I set. It is clear that as random forest increase n_estimator, it works well because it observe more train sets. For KNeighborsClassifier, it chose n_neighbors=93, it is pretty high, considering that default is 5. I think it is because we have a lot of categorical features. Overall, I expected to RandomForestClassifier works better than KNeighborsClassifier and, in this practice, it was actually true. However, I got f1_score 0.657, which is not good accuracy for the dataset. In my opinion, features were not significantly affected the target. One of the reason for the low f1 score is imbalanced data but I don't think it is in my project. My data is distributed in a good shape. If you see from the confusion matrix, you can see that for the \"draw\" game, it is relatively high false positive and false negative rate compared to \"Home team win\" and \"Away team win\" games. It shows that predicting \"draw\" game is harder and it affected the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sustained-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='brute', leaf_size=19, n_neighbors=93,\n",
      "                     weights='distance')\n",
      "RandomForestClassifier(max_depth=93, min_samples_leaf=2, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters used\n",
    "print(kn_rand_cv.best_estimator_.get_params()['kn'])\n",
    "print(rf_rand_cv.best_estimator_.get_params()['rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "technological-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[299,  96,  44],\n",
       "       [111, 158, 109],\n",
       "       [ 59, 145, 546]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
